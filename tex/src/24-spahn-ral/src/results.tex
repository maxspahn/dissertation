\section{Experimental results}
\label{sec:results}

In this section, we explain our implementation of the
presented methods and present quantitative
comparisons for three simulation environments, namely a
holonomic ground robot without and with moving obstacles,
see \cref{fig:point_robot_case}, a robotic manipulator, see
\cref{fig:panda_case}.
Unless stated otherwise, we evaluate 50 cases with different
noise levels $\sigma$. The noisy signal is generated using a
Gaussian distribution centered around the unoisy sensor
data. Specifically, as we use point clouds as inputs to all
presented methods, we have \np{} 3D points to form a
\pointcloud{}. The zero-mean, white noise with variance
$\sigma$ is added to each point to form the noisy
$\pointcloud_{\sigma}$. This noisy sensor data is then used
in the different methods, for computing the \ac{fsd}, the
\ac{sdf}, and no further processing is done for the raw
sensor data.

The performance is measured 
in terms of success, solver time and execution time to reach the goal.
Importantly, the solver time reported in this work does not
include the computation of the environment representation.
For \ac{sdf} however, we included the computation of the
numerical gradient because it is \ac{fabrics}-specific.
Lastly, 
we evaluate the methods in the real world using a
manipulator, see \cref{fig:real_panda},
and a holonomic ground robot, see \cref{fig:real_dingo}.
%
\begin{figure}[ht]
  \begin{subfigure}{0.5\linewidth}
    \includegraphics[width=0.95\linewidth]{point_robot_sim/point_robot_dynamic_case.png}
    \caption{Ground robot case}
    \label{fig:point_robot_case}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \includegraphics[width=0.95\textwidth]{panda_sim/panda_static_case.png}
    \caption{Robotic manipulator case}
    \label{fig:panda_case}
  \end{subfigure}%
  \caption{Simulation cases for the ground robot and the robotic manipulator.}
  \label{fig:simulation_cases}
\end{figure}
%
\begin{figure}[ht]
  \begin{subfigure}{0.5\linewidth}
    \includegraphics[width=0.95\linewidth]{dingo_real/dingo_setup.png}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \includegraphics[width=0.95\linewidth]{dingo_real/dingo.png}
  \end{subfigure}%
  \caption{Real ground robot used to run the experiments.
  For the real-world experiment, we used a Clearpath Dingo
  with a Velodyne VLP16 mounted on top (left). The
  real-world experiment shows the Dingo navigating through
  an environment where a human throws in obstacles (right).
  }
  \label{fig:real_dingo}
\end{figure}
%
\paragraph{Details on implementation}
%
\begin{figure}[ht]
  \centering
  \input{src/24-spahn-ral/img/methods/inkscape/composition_tex.pdf_tex}
  \caption{Composition of symbolic \ac{fabrics} and runtime loop.}
  \label{fig:composition_symbolic_fabrics}
\end{figure}
%
The implementation used in this work uses symbolic
pre-computation of \ac{fabrics}. In this symbolic
interpretation, the composition of the different behaviors
is performed before runtime in a symbolic way, see
\cref{fig:composition_symbolic_fabrics}. The implementation
is identical to the one used
in \cite{spahn2023autotuning}. The code can be found at
\href{www.github.com/tud-amr/fabrics}{Geometric Fabrics}. The simulation
environment as well as the algorithm for computing the \ac{fsd}, \ac{sdf}
and the raw Lidar data can be found as part of
\href{www.github.com/maxspahn/gym_envs_urdf}{urdfenvs}. For the real world
experiments, we used a ROS bridge and used the same
implementation to process the point clouds, generated by
either a Velodyne VLP-16 mounted on the robot, see
\cref{fig:real_dingo}, or by an occupancy grid build using
the octomap package \cite{Hornung2013}.

\subsection{Ground robot}
\label{sub:point_robot}

When comparing explicit environment representations with the proposed techniques
using noise-free sensor data ($\sigma=0.0$), \acp{sdf} demonstrate the highest
success rate. This is likely due to the \textit{guidance} provided by the
\ac{sdf}'s gradient information. Interestingly, the success
rate for an explicit environment representation increases
with the noise level. Potentially, the noisy sensor data is
able to push the robot out of local minima, which were
reported to be a problem for \ac{fabrics} in
\cite{Spahn2023}. The more implicit representations suffer
from the noise increase, most dramatically for the
\ac{sdf} representation, which becomes unusable around a
noise level of $\sigma=0.1$. When exposing all methods to a
dynamic environment (two moving obstacles), the explicit
representation has degrading performance, e.g. without noise 42/50 (static) to
38/50 (dynamic), see
\cref{fig:point_robot_sim_success_dynamic}.
The implicit representations show a similar success rate
across static and dynamic environments.
% static 42,40,38,34
% dynamic 38,42,44,35
Implicit
representations are hardly effected by the dynamic
character. This confirms our hypothesis that implicit
representations are a good approach in human-shared,
changing environments. Moreover, this finding is in line with the findings in
\cite{Spahn2023} on the inability for the explicit
representation to avoid moving obstacles.

The goal reaching times remain similar across all approaches, which aligns with
expectations as the tuning is based on this criterion, as shown in
\cref{subfig:point_robot_sim_metrics}. However, \ac{sdf} and
raw sensor data have some outliers in the time to reach the
goal, which is likely due local minima or
over-conservative behavior in some cases.
While solver computation times are low
for all methods (between $0.5$ ms and $2.0$ ms), utilizing
\ac{sdf} shows the highest computational costs, see
\cref{subfig:point_robot_sim_metrics}. Such low solver
times allow the usage in real-time applications where high
reactivity is required.
%
\begin{figure*}[ht]
  \centering
  \input{src/24-spahn-ral/img/point_robot_sim/success_cluster_static.pgf}
  \caption{Success rates for ground robot in \textbf{static}
  environments for different noise level on sensor inputs.
  }%
  \label{fig:point_robot_sim_success_static}
\end{figure*}
%
\begin{figure*}[ht]
  \centering
  \input{src/24-spahn-ral/img/point_robot_sim/success_cluster_dynamic.pgf}
  \caption{Success rates for ground robot in
  \textbf{dynamic}
  environments for different noise level on sensor inputs.
  }%
  \label{fig:point_robot_sim_success_dynamic}
\end{figure*}
%
\begin{figure}[ht]
  \centering
  \begin{subfigure}{0.48\linewidth}
    \centering
    \input{src/24-spahn-ral/img/point_robot_sim/cluster_static_00/time2Goal_PointRobot_00.pgf}
    \label{subfig:point_robot_sim_time2Goal}
  \end{subfigure}
  \begin{subfigure}{0.48\linewidth}
    \centering
    \input{src/24-spahn-ral/img/point_robot_sim/cluster_static_00/solvertime_PointRobot_00.pgf}
    \label{subfig:point_robot_sim_solvertimes}
  \end{subfigure}%
  \caption{Evaluation metrics, goal reaching (left) and
  solvertimes (right), for the ground robot in simulation.
  }%
  \label{fig:point_robot_sim_metrics}
\end{figure}

\newpage

\subsection{Robotic manipulator}
\label{sub:manipulator}
%
For the experiments with the robotic manipulator, the
environment configuration was kept similar to the
experiments with the same arm in \cite{bhardwaj2022storm}.
The randomized experiments were obtained by randomly
selecting goal locations.
%
\begin{figure*}[ht]
  \centering
  \input{src/24-spahn-ral/img/panda_sim/success_cluster_static.pgf}
  \caption{Success rates for robotic manipulator in static
  environments for different noise level on sensor inputs.
  }%
  \label{fig:panda_robot_sim_success_static}
\end{figure*}
%

High success rates are achieved for all methods in static,
noise-free environments, as shown in \cref{fig:panda_robot_sim_success_static}.
As the noise level increases, success rates decrease for all
methods. Unlike implicit representations, an explicit environment
representation does not suffer from collisions as sensor
noise increases, but leads to higher limit-violation rates. 
Limit-violations are usually caused by a negative $\x$ value
in the collision spec, leading to infititly high repulsive
accelerations. 
This is a known issue for \ac{fabrics} and can be
mitigated by using a soft-max function to limit the
repulsive acceleration. However, this was not done in this
work to keep the comparison fair.
However, up to a noise level of
$\sigma=0.02$, success rates are still between
60\%(\ac{sdf}) and 90\% (raw sensor data). In terms of
execution time, all methods perform similarly, as expected
from the tuning process. Solver times are highest for
\ac{sdf} ($\approx 25.0$ ms) and below $10$ ms for the 
other methods, see \cref{subfig:panda_sim_solvertimes}.
The significantly higher solver times for \ac{sdf} are due
to the computation of the numerical gradient, which is
\ac{fabrics}-specific and thus included in the solver time.
This makes all methods suitable for real-time applications.
%
\begin{figure}[ht]
  \centering
  \begin{subfigure}{0.5\linewidth}
    \centering
    \input{src/24-spahn-ral/img/panda_sim/cluster_static_00/time2Goal_Panda_00.pgf}
    \caption{Goal reaching time}%
    \label{subfig:panda_sim_time2Goal}
  \end{subfigure}%
  \begin{subfigure}{0.5\linewidth}
    \centering
    \input{src/24-spahn-ral/img/panda_sim/cluster_static_00/solvertime_Panda_00.pgf}
    \caption{Solvertimes}%
    \label{subfig:panda_sim_solvertimes}
  \end{subfigure}%
  \caption{Evaluation metrics for robot manipulator in
    simulation.
  }%
  \label{fig:panda_sim_metrics}
\end{figure}

\subsection{Real-World Experiments} % (fold)
\label{sub:real_world_experiments}
%
We tested the methods presented in this paper in the
real-world using a Clearpath Dingo and a Franka
Emika Panda. 

\paragraph{Dingo}
For the Clearpath Dingo, we used a Velodyne
VLP16 to generate the point cloud data in the ground plane,
effectively discarding information for higher z-values. We
use a resolution of 1 ray/degree. The method is wrapped into
a ros-node where new control actions are commanded at
$40$Hz. We test the methods in an
arbitrary setup environment where obstacles are placed and
thrown in front of the robot by a human, see
\cref{fig:real_dingo}. For detailed understanding of
the setup, we refer to the accompanied video material. The
robot is able to quickly adapt to the obstructions and
safely navigates the environment. However, similar to the
findings in simulation, when exposed to local minima the
robot is not able to escape. This is due to the fact that
all methods presented in this paper are highly reactive, exhibiting
no time-horizon planning into the future. This is well in line with
existing literature on the framework of \ac{fabrics} and
emphasizes the ideal usage of \ac{fabrics} as a safe
medium on which attractor policies can act \cite{wyk2024geometric}.

\paragraph{Panda}
%
\begin{figure}[ht]
  \includegraphics[width=0.95\linewidth]{panda_real/fsd_panda.png}
  \caption{Real robotic manipulator used to run the experiments. A
    Franka Emika Panda is confronted with an unknown shelf
    environment in a supermarket. Arrows indicate the
    normals of the planes obtained by the \ac{fsd}.
    Different colors indicate different links on the robotic
    arm.
  }
  \label{fig:real_panda}
\end{figure}
%
For the Franka Emika Panda, we used the octomap package to
generate the occupancy grid. The method is wrapped into a
ros-node where new control actions are commanded at $40$Hz.
We used three collision links on the robots for collision
avoidance, see \cref{fig:real_panda} for the realization of
\ac{fsd}. The experiments reveal that implicit environment
representations allow for collision-free motion of robotics
arms without the need for a complex perception pipeline.

