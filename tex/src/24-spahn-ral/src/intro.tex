\section{Introduction}
\label{sec:ral24_intro}
%
As robots make their way into human shared environments,
fast reactive behavior is needed to ensure that collisions are avoided
at all time. \acf{tg} is commonly formulated as a receding
horizon optimization problem, where the robot's trajectory
is optimized over a short time horizon. Such methods are
known as \acf{mpc} and have shown great success for autonomous
vehicles and drones where the dimension of the configuration
space remains small. For higher dimensional
configuration spaces, e.g. manipulators and mobile
manipulators, the computational cost of \ac{mpc} scale
poorly, leading to slower computation cycles and ultimately
to a less reactive behavior. \acf{fabrics} offer an
alternative to these approaches. Based on differential
geometry, policies are composed of several components to form a highly reactive
and fast behavior. However, the composition of \ac{fabrics} of
individual obstacle avoidance geometries is limited to simple geometric shapes,
such that a differentiable distance function can easily be
formulated. This \textit{explicit} environment
representation
sets a challenging requirement on the perception part of the motion generation
pipeline. In this work, we present and analyze three
different representations of the environment to 
overcome this drawback, namely \acf{fsd}, 
\acfp{sdf} and raw sensor data, from visual sensors, such as
cameras or Lidars, into the framework of
\ac{fabrics}. We refer to these representations as
\textit{implicit}.
Generally, the more implicit an environment representation is, the more
computational costs are moved from the perception pipeline to the planner.
In the process, we derive essential extensions to the framework and
analyze strengths and weaknesses of the individual methods. To summarize, this
paper makes the following contributions:
\begin{itemize}
  \item We integrate implicit representation of the environment into the
    framework of \ac{fabrics}, namely \ac{fsd}, \ac{sdf}
    and raw sensor data.
  \item We derive how numerical gradients can be used for pullback operations
    which are essential in the composition of \ac{fabrics}.
  \item We analyze the strengths and weaknesses of the three representations in
    different environments, including moving obstacles, and
    with various robot morphologies.
  \item We present real-world experiments illustrating the power of our
    open-source implementation.
\end{itemize}

% \section{Environment representations}
% \label{sec:environment_representations}
% 
% All above described methods rely on some form of environment
% representation. For example, the inequality constraints in
% \ac{mpc} formulations responsible for collision avoidance
% rely on a distance function between the robot and the
% obstacles. Path planning methods, as described above, 
% also require an environment representation, such that
% collision checking can accept or reject new samples. In
% geometric approaches, such as \ac{apf}, \ac{rmp} and
% \ac{fabrics}, distance functions are also necessary.
% For primitive shapes, such as spheres and boxes, distances
% can be computed in closed form. When working in dynamic
% environments, robots perceive their environment using vision
% sensors, such as cameras, or range sensors, such as LiDAR.
% Classifying the environment into primitive shapes is a
% challenging task, especially when the environment is
% cluttered and parts are occluded. A different approach to
% collision avoidance relies on more implicit representations
% of the environments --the most implicit would be raw sensor
% data. In the following, we recall some works that focus on
% such representations in the context of \ac{tg}.


