\section{Related Work}

Robotic mobile manipulation stands as a dynamic and expansive field of research,
spurred by diverse potential applications and further fueled by prestigious
international competitions, such as DARPAâ€™s Robotics Challenge
\cite{darpa_challenge}, RoboCup@Home~\cite{robocup_home}, the Amazon Picking
Challenge \cite{corbato2018integrating}, and RoboCup@Work \cite{robocup_work}.
These competitions are tailored to address distinct challenges and performance
criteria. Numerous research projects have yielded a significant number of
various mobile manipulation platforms. For an exhaustive overview of wheeled
mobile manipulation systems and the associated challenges, readers can refer to
\cite{overview1,overview2}.
In contrast to the aforementioned platforms, we focus on combining commercial off-the-shelf components with
little to no modifications to address the specific application.

A supermarket mobile manipulator has been presented in
\cite{toyota2023} with a special focus on metrics in real-world settings and quantitative field experiments. Similar long-term fetch and carry
experiments, yet in different environments, were carried out by Domel et
al.~\cite{domel2017toward} in a factory environment and by Stibinger et
al.~\cite{vstibinger2021mobile} in an outdoor competition to pick up and place
simulated construction materials. Instead of relying on a  Model Predictive
Control formulation, such as~\cite{minniti2021model} for motion
planning and control, we deploy a reactive trajectory generation method
\cite{ratliff2023fabrics}, and a task planning and execution approach that is
 adaptive in the presence of disturbances.
Additionally, we use learning from demonstration to easily teach new products. This approach seems extendable to very different tasks
in the long run.


Object picking with manipulators
is a well-studied problem. Early approaches rely on engineered components and
split detection and grasping into separate tasks. An adapation of STOMP
\cite{Kalakrishnan2011} for mobile manipulation was presented in
\cite{bormann2019towards}. Here, motions of base and arm are sequenced.
Manipulation tasks, including item retrieval, can also be approached from
data-driven perspectives. Deep reinforcement learning was used to achieve object
picking with a mobile manipulator in non-cluttered environments
\cite{wang2020learning}. In contrast, learning from teleoperation data showed
impressive results for dexterous manipulation tasks \cite{zhao2023learning}. The
work was extended to mobile manipulation in \cite{fu2024mobile}. While the
results are impressive, each task is trained individually, and no safety
statements can be made. In contrast, our work relies on engineered components
enhanced with learning-from-demonstration techniques to achieve safe and robust
mobile manipulation in a supermarket environment.



